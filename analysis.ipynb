{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from github import Github\n",
    "from dotenv import load_dotenv\n",
    "import networkx as nx\n",
    "import csv\n",
    "\n",
    "# Create an empty graph\n",
    "graph = nx.Graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file and read the data for users\n",
    "with open('dataset/users.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0: # Skip the header columns\n",
    "            continue\n",
    "\n",
    "        # transform the string of repositories into an array of strings\n",
    "        row[2] = [x for x in row[2].replace(' ', '').replace('[', '').replace(']', '').replace('\\'', '').split(',')]\n",
    "\n",
    "        # Add the node with data from the first column\n",
    "        graph.add_node(row[0], name=row[1], repos=row[2], color=\"#7FB2FD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file and read the data for repositories\n",
    "with open('dataset/repos.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0: # Skip the header columns\n",
    "            continue\n",
    "\n",
    "        # transform the string of languages into an array of strings\n",
    "        row[2] = [x for x in row[2].replace(' ', '').replace('[', '').replace(']', '').replace('\\'', '').split(',')]\n",
    "\n",
    "        \"\"\" print(\"row\", i, \": \", row)\n",
    "        print(\"row[0] (repository ID): \", row[0])\n",
    "        print(\"row[1] (repository name): \", row[1])\n",
    "        print(\"row[2] (languages): \", row[2]) \"\"\"\n",
    "\n",
    "        # Add the node with data from the first column\n",
    "        graph.add_node(row[0], name=row[1], languages=row[2], color=\"#FF8CCD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an edge between users and repositories\n",
    "for node in graph.nodes:\n",
    "    # if node starts with \"U\"\n",
    "    if node[0] == \"u\":\n",
    "        # for each repository in the user's list of repositories\n",
    "        for repo in graph.nodes[node]['repos']:\n",
    "            # add an edge between the user and the repository\n",
    "            graph.add_edge(node, repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4432\n",
      "Number of edges: 6375\n"
     ]
    }
   ],
   "source": [
    "# Print the number of nodes and edges\n",
    "print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "print(\"Number of edges:\", graph.number_of_edges())\n",
    "\n",
    "# Print the neighbors of a node\n",
    "# print(\"Neighbors of node 1:\", list(G.neighbors(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph using color property to distinguish users and repositories\n",
    "#nx.draw(graph, with_labels=True, node_color=[graph.nodes[node]['color'] for node in graph.nodes], node_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Degree centrality of first 10 nodes in descending order:\n",
      "u_1710 0.22432859399684044\n",
      "u_1387 0.22297449785601445\n",
      "u_2712 0.009027307605506657\n",
      "u_776 0.006093432633716994\n",
      "u_1205 0.004062288422477996\n",
      "u_1461 0.0038366057323403293\n",
      "u_2125 0.003610923042202663\n",
      "u_2180 0.003610923042202663\n",
      "u_3060 0.002933874971789664\n",
      "u_3222 0.002933874971789664\n",
      "\n",
      "Mean degree centrality for users: 0.0004184779376462035\n",
      "\n",
      "Degree centrality of first 10 nodes in descending order:\n",
      "r_667 0.07086436470322727\n",
      "r_963 0.05055292259083728\n",
      "r_126 0.028887384337621305\n",
      "r_216 0.028887384337621305\n",
      "r_76 0.023696682464454975\n",
      "r_2 0.02279395170390431\n",
      "r_3 0.020537124802527645\n",
      "r_225 0.019183028661701646\n",
      "r_969 0.018731663281426315\n",
      "r_115 0.01828029790115098\n",
      "\n",
      "Mean degree centrality for repositories: 0.001447411619343704\n"
     ]
    }
   ],
   "source": [
    "# Calculate the degree centrality of all nodes\n",
    "degree_centrality = nx.degree_centrality(graph)\n",
    "\n",
    "# divide the degree centrality \n",
    "users_degree_centrality = { k: v for k, v in degree_centrality.items() if k.startswith('u_')}\n",
    "repos_degree_centrality = { k: v for k, v in degree_centrality.items() if k.startswith('r_')}\n",
    "\n",
    "# Print the degree centrality of first 10 users in descending order\n",
    "print(\"\\nDegree centrality of first 10 nodes in descending order:\")\n",
    "for node in sorted(users_degree_centrality, key=users_degree_centrality.get, reverse=True)[:10]:\n",
    "    print(node, users_degree_centrality[node])\n",
    "\n",
    "# show mean degree centrality for users\n",
    "print(\"\\nMean degree centrality for users:\", sum(users_degree_centrality.values())/len(users_degree_centrality))\n",
    "\n",
    "# Print the degree centrality of first 10 repositories in descending order\n",
    "print(\"\\nDegree centrality of first 10 nodes in descending order:\")\n",
    "for node in sorted(repos_degree_centrality, key=repos_degree_centrality.get, reverse=True)[:10]:\n",
    "    print(node, repos_degree_centrality[node])\n",
    "\n",
    "# show mean degree centrality for repositories\n",
    "print(\"\\nMean degree centrality for repositories:\", sum(repos_degree_centrality.values())/len(repos_degree_centrality))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the betweenness centrality of all nodes\n",
    "betweenness_centrality = nx.betweenness_centrality(graph)\n",
    "\n",
    "# Calculate the betweenness centrality of users nodes\n",
    "users_betweenness_centrality = { k: v for k, v in betweenness_centrality.items() if k.startswith('u_')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node u_1710 has betweenness centrality 0.4703289313283779\n",
      "Node u_1387 has betweenness centrality 0.4398901534290559\n",
      "Node u_2712 has betweenness centrality 0.009618500765823849\n",
      "Node u_2125 has betweenness centrality 0.004504485559402676\n",
      "Node u_2180 has betweenness centrality 0.003881150205018476\n",
      "Node u_3174 has betweenness centrality 0.0030214588822351637\n",
      "Node u_957 has betweenness centrality 0.0025193007937907705\n",
      "Node u_1207 has betweenness centrality 0.0024694943601352936\n",
      "Node u_776 has betweenness centrality 0.002030059550218193\n",
      "Node u_28 has betweenness centrality 0.001999912391358061\n",
      "\n",
      "Mean betweenness centrality for users: 0.00028614468189174115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the betweenness centrality of each node\n",
    "for node, centrality in sorted(users_betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(\"Node\", node, \"has betweenness centrality\", centrality)\n",
    "\n",
    "# show mean betweenness centrality for users\n",
    "print(\"\\nMean betweenness centrality for users:\", sum(users_betweenness_centrality.values())/len(users_betweenness_centrality))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigenvector centrality of first 10 nodes in descending order:\n",
      "Node r_667 has eigenvector centrality 0.02807241600112121\n",
      "Node r_963 has eigenvector centrality 0.0252872002485827\n",
      "Node r_126 has eigenvector centrality 0.02508444065051212\n",
      "Node r_204 has eigenvector centrality 0.024918586221542628\n",
      "Node r_969 has eigenvector centrality 0.02484594166364357\n",
      "Node r_3 has eigenvector centrality 0.024744005513770605\n",
      "Node r_41 has eigenvector centrality 0.024621133427994935\n",
      "Node r_252 has eigenvector centrality 0.02459630822116519\n",
      "Node r_0 has eigenvector centrality 0.02452737750133048\n",
      "Node r_115 has eigenvector centrality 0.024420314891656622\n",
      "\n",
      "Eigenvector centrality of first 10 nodes in descending order:\n",
      "Node u_1710 has eigenvector centrality 0.49917648037912005\n",
      "Node u_1387 has eigenvector centrality 0.4976560737491123\n",
      "Node u_2712 has eigenvector centrality 0.021178422969835194\n",
      "Node u_776 has eigenvector centrality 0.01404028576450716\n",
      "Node u_1205 has eigenvector centrality 0.009409539530923217\n",
      "Node u_2125 has eigenvector centrality 0.008625366235509292\n",
      "Node u_1461 has eigenvector centrality 0.008589875908040364\n",
      "Node u_2180 has eigenvector centrality 0.008390442787245711\n",
      "Node u_3060 has eigenvector centrality 0.0068374099322502475\n",
      "Node u_3222 has eigenvector centrality 0.006559110191899708\n"
     ]
    }
   ],
   "source": [
    "# Calculate the eigenvector centrality of all nodes\n",
    "eigenvector_centrality = nx.eigenvector_centrality(graph, max_iter=1000)\n",
    "\n",
    "# Calculate the eigenvector centrality of repos nodes\n",
    "repos_eigenvector_centrality = { k: v for k, v in eigenvector_centrality.items() if k.startswith('r_')}\n",
    "\n",
    "# Calculate the eigenvector centrality of users nodes\n",
    "users_eigenvector_centrality = { k: v for k, v in eigenvector_centrality.items() if k.startswith('u_')}\n",
    "\n",
    "# Print the eigenvector centrality of repos nodes\n",
    "print(\"\\nEigenvector centrality of first 10 nodes in descending order:\")\n",
    "for node, centrality in sorted(repos_eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(\"Node\", node, \"has eigenvector centrality\", centrality)\n",
    "\n",
    "# Print the eigenvector centrality of users nodes\n",
    "print(\"\\nEigenvector centrality of first 10 nodes in descending order:\")\n",
    "for node, centrality in sorted(users_eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(\"Node\", node, \"has eigenvector centrality\", centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Clustering coefficient of repos nodes by languages of repositories:\n",
      "Language Logos has clustering coefficient 0.024420314891656622\n",
      "Language Slim has clustering coefficient 0.024420314891656622\n",
      "Language RichTextFormat has clustering coefficient 0.02439207166182593\n",
      "Language CMake has clustering coefficient 0.02430512933764281\n",
      "Language M4 has clustering coefficient 0.024218187013459694\n",
      "Language Ada has clustering coefficient 0.024218187013459694\n",
      "Language Pascal has clustering coefficient 0.024218187013459694\n",
      "Language DIGITALCommandLanguage has clustering coefficient 0.024218187013459694\n",
      "Language DTrace has clustering coefficient 0.024218187013459694\n",
      "Language CLIPS has clustering coefficient 0.024218187013459694\n"
     ]
    }
   ],
   "source": [
    "# Calculate the clustering coefficient of repos nodes by languages of repositories\n",
    "repos_clustering_coefficient = {}\n",
    "for node in repos_eigenvector_centrality:\n",
    "    # get the languages of the repository\n",
    "    languages = graph.nodes[node]['languages']\n",
    "    # for each language\n",
    "    for language in languages:\n",
    "        # if the language is not in the dictionary\n",
    "        if language not in repos_clustering_coefficient:\n",
    "            # add the language as a key and the eigenvector centrality as a value\n",
    "            repos_clustering_coefficient[language] = [repos_eigenvector_centrality[node]]\n",
    "        # if the language is already in the dictionary\n",
    "        else:\n",
    "            # append the eigenvector centrality to the list of values\n",
    "            repos_clustering_coefficient[language].append(repos_eigenvector_centrality[node])\n",
    "\n",
    "# Print the clustering coefficient of repos nodes by languages of repositories\n",
    "print(\"\\nClustering coefficient of repos nodes by languages of repositories:\")\n",
    "for language, centrality in sorted(repos_clustering_coefficient.items(), key=lambda x: sum(x[1])/len(x[1]), reverse=True)[:10]:\n",
    "    print(\"Language\", language, \"has clustering coefficient\", sum(centrality)/len(centrality))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'homophily'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [84], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Calculate homophily of nodes\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m homophily \u001b[39m=\u001b[39m nx\u001b[39m.\u001b[39mhomophily(graph)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx' has no attribute 'homophily'"
     ]
    }
   ],
   "source": [
    "# Calculate homophily of nodes\n",
    "# Create an example graph\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([(1, 2), (1, 3), (2, 3), (3, 4)])\n",
    "\n",
    "# Create sets for users and repos\n",
    "users = set([1, 2, 3])\n",
    "repos = set([4])\n",
    "\n",
    "# Add attributes to the nodes\n",
    "for node in G.nodes():\n",
    "    if node in users:\n",
    "        G.nodes[node]['user'] = 'user' + str(node)\n",
    "        G.nodes[node]['repos'] = ['repo' + str(node) + '_1', 'repo' + str(node) + '_2']\n",
    "    if node in repos:\n",
    "        G.nodes[node]['name'] = 'repo' + str(node)\n",
    "        G.nodes[node]['languages'] = ['python', 'javascript']\n",
    "\n",
    "# Compute Jaccard similarity for each edge between users\n",
    "for u, v, d in G.edges(data=True):\n",
    "    if G.nodes[u]['user'] is not None and G.nodes[v]['user'] is not None:\n",
    "        languages_u = set(G.nodes[u]['languages'])\n",
    "        languages_v = set(G.nodes[v]['languages'])\n",
    "        d['similarity'] = len(languages_u.intersection(languages_v)) / len(languages_u.union(languages_v))\n",
    "\n",
    "# Print the similarity values for each edge\n",
    "print(nx.get_edge_attributes(G, 'similarity'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'networkx' has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [85], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m nx\u001b[39m.\u001b[39minfo(graph)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'networkx' has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "# Calculate structural equivalence of nodes\n",
    "# Create an example graph\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)])\n",
    "\n",
    "# Create sets for users and repos\n",
    "users = set([1, 2, 3])\n",
    "repos = set([4,5,6])\n",
    "\n",
    "# Add edges between users and repos\n",
    "G.add_edges_from([(1, 4), (1, 5), (2, 5), (2, 6), (3, 6)])\n",
    "\n",
    "# Compute structural equivalence for each pair of users\n",
    "for u in users:\n",
    "    for v in users:\n",
    "        if u < v:\n",
    "            repos_u = set(G.neighbors(u)) & repos\n",
    "            repos_v = set(G.neighbors(v)) & repos\n",
    "            sim = len(repos_u.intersection(repos_v)) / len(repos_u.union(repos_v))\n",
    "            print(\"Structural equivalence between user {} and user {}: {}\".format(u, v, sim))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

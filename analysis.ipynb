{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from github import Github\n",
    "from dotenv import load_dotenv\n",
    "import networkx as nx\n",
    "import csv\n",
    "\n",
    "# Create an empty graph\n",
    "graph = nx.Graph()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file and read the data for users\n",
    "with open('dataset/users.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0: # Skip the header columns\n",
    "            continue\n",
    "\n",
    "        # transform the string of repositories into an array of strings\n",
    "        row[2] = [x for x in row[2].replace(' ', '').replace('[', '').replace(']', '').replace('\\'', '').split(',')]\n",
    "\n",
    "        # Add the node with data from the first column\n",
    "        graph.add_node(row[0], name=row[1], repos=row[2], color=\"#7FB2FD\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the CSV file and read the data for repositories\n",
    "with open('dataset/repos.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0: # Skip the header columns\n",
    "            continue\n",
    "\n",
    "        # transform the string of languages into an array of strings\n",
    "        row[2] = [x for x in row[2].replace(' ', '').replace('[', '').replace(']', '').replace('\\'', '').split(',')]\n",
    "\n",
    "        \"\"\" print(\"row\", i, \": \", row)\n",
    "        print(\"row[0] (repository ID): \", row[0])\n",
    "        print(\"row[1] (repository name): \", row[1])\n",
    "        print(\"row[2] (languages): \", row[2]) \"\"\"\n",
    "\n",
    "        # Add the node with data from the first column\n",
    "        graph.add_node(row[0], name=row[1], languages=row[2], color=\"#FF8CCD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add an edge between users and repositories\n",
    "for node in graph.nodes:\n",
    "    # if node starts with \"U\"\n",
    "    if node[0] == \"u\":\n",
    "        # for each repository in the user's list of repositories\n",
    "        for repo in graph.nodes[node]['repos']:\n",
    "            # add an edge between the user and the repository\n",
    "            graph.add_edge(node, repo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 4432\n",
      "Number of edges: 6375\n"
     ]
    }
   ],
   "source": [
    "# Print the number of nodes and edges\n",
    "print(\"Number of nodes:\", graph.number_of_nodes())\n",
    "print(\"Number of edges:\", graph.number_of_edges())\n",
    "\n",
    "# Print the neighbors of a node\n",
    "# print(\"Neighbors of node 1:\", list(G.neighbors(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the graph using color property to distinguish users and repositories\n",
    "#nx.draw(graph, with_labels=True, node_color=[graph.nodes[node]['color'] for node in graph.nodes], node_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Degree centrality of first 10 nodes in descending order:\n",
      "u_1710 0.22432859399684044\n",
      "u_1387 0.22297449785601445\n",
      "u_2712 0.009027307605506657\n",
      "u_776 0.006093432633716994\n",
      "u_1205 0.004062288422477996\n",
      "u_1461 0.0038366057323403293\n",
      "u_2125 0.003610923042202663\n",
      "u_2180 0.003610923042202663\n",
      "u_3060 0.002933874971789664\n",
      "u_3222 0.002933874971789664\n",
      "\n",
      "Mean degree centrality for users: 0.0004184779376462035\n",
      "\n",
      "Degree centrality of first 10 nodes in descending order:\n",
      "r_667 0.07086436470322727\n",
      "r_963 0.05055292259083728\n",
      "r_126 0.028887384337621305\n",
      "r_216 0.028887384337621305\n",
      "r_76 0.023696682464454975\n",
      "r_2 0.02279395170390431\n",
      "r_3 0.020537124802527645\n",
      "r_225 0.019183028661701646\n",
      "r_969 0.018731663281426315\n",
      "r_115 0.01828029790115098\n",
      "\n",
      "Mean degree centrality for repositories: 0.001447411619343704\n"
     ]
    }
   ],
   "source": [
    "# Calculate the degree centrality of all nodes\n",
    "degree_centrality = nx.degree_centrality(graph)\n",
    "\n",
    "# divide the degree centrality \n",
    "users_degree_centrality = { k: v for k, v in degree_centrality.items() if k.startswith('u_')}\n",
    "repos_degree_centrality = { k: v for k, v in degree_centrality.items() if k.startswith('r_')}\n",
    "\n",
    "# Print the degree centrality of first 10 users in descending order\n",
    "print(\"\\nDegree centrality of first 10 nodes in descending order:\")\n",
    "for node in sorted(users_degree_centrality, key=users_degree_centrality.get, reverse=True)[:10]:\n",
    "    print(node, users_degree_centrality[node])\n",
    "\n",
    "# show mean degree centrality for users\n",
    "print(\"\\nMean degree centrality for users:\", sum(users_degree_centrality.values())/len(users_degree_centrality))\n",
    "\n",
    "# Print the degree centrality of first 10 repositories in descending order\n",
    "print(\"\\nDegree centrality of first 10 nodes in descending order:\")\n",
    "for node in sorted(repos_degree_centrality, key=repos_degree_centrality.get, reverse=True)[:10]:\n",
    "    print(node, repos_degree_centrality[node])\n",
    "\n",
    "# show mean degree centrality for repositories\n",
    "print(\"\\nMean degree centrality for repositories:\", sum(repos_degree_centrality.values())/len(repos_degree_centrality))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the betweenness centrality of all nodes\n",
    "betweenness_centrality = nx.betweenness_centrality(graph)\n",
    "\n",
    "# Calculate the betweenness centrality of users nodes\n",
    "users_betweenness_centrality = { k: v for k, v in betweenness_centrality.items() if k.startswith('u_')}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node u_1710 has betweenness centrality 0.4703289313283779\n",
      "Node u_1387 has betweenness centrality 0.4398901534290559\n",
      "Node u_2712 has betweenness centrality 0.009618500765823849\n",
      "Node u_2125 has betweenness centrality 0.004504485559402676\n",
      "Node u_2180 has betweenness centrality 0.003881150205018476\n",
      "Node u_3174 has betweenness centrality 0.0030214588822351637\n",
      "Node u_957 has betweenness centrality 0.0025193007937907705\n",
      "Node u_1207 has betweenness centrality 0.0024694943601352936\n",
      "Node u_776 has betweenness centrality 0.002030059550218193\n",
      "Node u_28 has betweenness centrality 0.001999912391358061\n",
      "\n",
      "Mean betweenness centrality for users: 0.00028614468189174115\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Print the betweenness centrality of each node\n",
    "for node, centrality in sorted(users_betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(\"Node\", node, \"has betweenness centrality\", centrality)\n",
    "\n",
    "# show mean betweenness centrality for users\n",
    "print(\"\\nMean betweenness centrality for users:\", sum(users_betweenness_centrality.values())/len(users_betweenness_centrality))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Eigenvector centrality of first 10 nodes in descending order:\n",
      "Node r_667 has eigenvector centrality 0.02807241600112121\n",
      "Node r_963 has eigenvector centrality 0.0252872002485827\n",
      "Node r_126 has eigenvector centrality 0.02508444065051212\n",
      "Node r_204 has eigenvector centrality 0.024918586221542628\n",
      "Node r_969 has eigenvector centrality 0.02484594166364357\n",
      "Node r_3 has eigenvector centrality 0.024744005513770605\n",
      "Node r_41 has eigenvector centrality 0.024621133427994935\n",
      "Node r_252 has eigenvector centrality 0.02459630822116519\n",
      "Node r_0 has eigenvector centrality 0.02452737750133048\n",
      "Node r_115 has eigenvector centrality 0.024420314891656622\n",
      "\n",
      "Eigenvector centrality of first 10 nodes in descending order:\n",
      "Node u_1710 has eigenvector centrality 0.49917648037912005\n",
      "Node u_1387 has eigenvector centrality 0.4976560737491123\n",
      "Node u_2712 has eigenvector centrality 0.021178422969835194\n",
      "Node u_776 has eigenvector centrality 0.01404028576450716\n",
      "Node u_1205 has eigenvector centrality 0.009409539530923217\n",
      "Node u_2125 has eigenvector centrality 0.008625366235509292\n",
      "Node u_1461 has eigenvector centrality 0.008589875908040364\n",
      "Node u_2180 has eigenvector centrality 0.008390442787245711\n",
      "Node u_3060 has eigenvector centrality 0.0068374099322502475\n",
      "Node u_3222 has eigenvector centrality 0.006559110191899708\n"
     ]
    }
   ],
   "source": [
    "# Calculate the eigenvector centrality of all nodes\n",
    "eigenvector_centrality = nx.eigenvector_centrality(graph, max_iter=1000)\n",
    "\n",
    "# Calculate the eigenvector centrality of repos nodes\n",
    "repos_eigenvector_centrality = { k: v for k, v in eigenvector_centrality.items() if k.startswith('r_')}\n",
    "\n",
    "# Calculate the eigenvector centrality of users nodes\n",
    "users_eigenvector_centrality = { k: v for k, v in eigenvector_centrality.items() if k.startswith('u_')}\n",
    "\n",
    "# Print the eigenvector centrality of repos nodes\n",
    "print(\"\\nEigenvector centrality of first 10 nodes in descending order:\")\n",
    "for node, centrality in sorted(repos_eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(\"Node\", node, \"has eigenvector centrality\", centrality)\n",
    "\n",
    "# Print the eigenvector centrality of users nodes\n",
    "print(\"\\nEigenvector centrality of first 10 nodes in descending order:\")\n",
    "for node, centrality in sorted(users_eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:10]:\n",
    "    print(\"Node\", node, \"has eigenvector centrality\", centrality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the clustering coefficient of repos nodes by language\n",
    "repos_clustering_coefficient = {}\n",
    "for node in repos_eigenvector_centrality:\n",
    "    # get the language of the repository\n",
    "    language = graph.nodes[node]['languages'][0]\n",
    "    # if the language is not in the dictionary, add it\n",
    "    if language not in repos_clustering_coefficient:\n",
    "        repos_clustering_coefficient[language] = []\n",
    "    # add the clustering coefficient of the repository to the list of clustering coefficients of the language\n",
    "    repos_clustering_coefficient[language].append(nx.clustering(graph, node))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
